{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Oct  5 17:38:16 2019\n",
    "\n",
    "@author: unalunsal\n",
    "https://www.eia.gov/totalenergy/data/browser/?tbl=T09.09#/?f=M\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.io import show\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, RangeTool\n",
    "from bokeh.plotting import figure\n",
    "#from bokeh.sampledata.stocks import AAPL\n",
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model inputs \n",
    "train_size = 530\n",
    "vec_node = 20\n",
    "step_ahead = 0\n",
    "batch_size = 256\n",
    "buffer_size = 10000\n",
    "internal_eval = 200\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\unalu\\Desktop\\eia\\MER_T09_09.csv')\n",
    "df['YYYYMM'] = df['YYYYMM'].astype(str).values # convert integer to string \n",
    "\n",
    "df = df.loc[~df['YYYYMM'].str.endswith('13'),:]  # drop the annual values \n",
    " \n",
    "df['YYYYMM'] = pd.to_datetime(df['YYYYMM'], format='%Y%m', errors='coerce').dropna() # convert string to datetime\n",
    "\n",
    "df_clerdus = df.loc[df['MSN'] == 'CLERDUS',]\n",
    "\n",
    "dates = df_clerdus['YYYYMM']\n",
    "\n",
    "data_ts = df_clerdus['Value'].values.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
    "  data = []\n",
    "  labels = []\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i)\n",
    "    # Reshape data from (history_size,) to (history_size, 1)\n",
    "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "    labels.append(dataset[i+target_size])\n",
    "  return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "lstm_pred = np.array([])\n",
    "for i in range(train_size, len(data_ts)):   \n",
    "    data_ts_mean = data_ts[:i].mean()\n",
    "    data_ts_std = data_ts[:i].std()\n",
    "    data_ts = (data_ts-data_ts_mean) / data_ts_std  \n",
    "\n",
    "    x_train_uni, y_train_uni = univariate_data(data_ts, 0, train_size, vec_node, step_ahead)\n",
    "    x_val_uni, y_val_uni = univariate_data(data_ts, train_size, None, vec_node, step_ahead)\n",
    "\n",
    "    train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
    "    train_univariate = train_univariate.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
    "    val_univariate = val_univariate.batch(batch_size).repeat()\n",
    "\n",
    "    lstm_mod = tf.keras.models.Sequential([\n",
    "                        tf.keras.layers.LSTM(8, input_shape=x_train_uni.shape[-2:]),\n",
    "                        tf.keras.layers.Dense(1)])\n",
    "    \n",
    "    lstm_mod.compile(optimizer='adam', loss='mae')\n",
    "    \n",
    "    lstm_mod.fit(train_univariate, epochs=epochs,\n",
    "                          steps_per_epoch=internal_eval,\n",
    "                          validation_data=val_univariate, validation_steps=50)\n",
    "    for x, y in val_univariate.take(3):\n",
    "        forecast = lstm_mod.predict(x)[0].item() * data_ts_std + data_ts_mean\n",
    "    lstm_pred = np.append(lstm_pred, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_ts = df_clerdus['Value'][:train_size].append(pd.Series(round(lstm_pred, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
